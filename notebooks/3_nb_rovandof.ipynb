{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "3224495c-70cd-4024-a5f3-77cfc602f6f2",
    "deepnote_cell_height": 76,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1060003,
    "execution_start": 1663212879207,
    "source_hash": "f30b975a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ejercicio III:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "453bea0a8e074e00b0e355b8db3c1224",
    "deepnote_cell_height": 788.625,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1663212879208,
    "source_hash": "19d75fbf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year  Día  Mes   valor\n",
      "0    2019    1  Ene    0.00\n",
      "1    2019    2  Ene  694.77\n",
      "2    2019    3  Ene  697.09\n",
      "3    2019    4  Ene  697.64\n",
      "4    2019    5  Ene    0.00\n",
      "..    ...  ...  ...     ...\n",
      "739  2020   27  Dic    0.00\n",
      "740  2020   28  Dic  710.26\n",
      "741  2020   29  Dic  710.64\n",
      "742  2020   30  Dic  711.24\n",
      "743  2020   31  Dic    0.00\n",
      "\n",
      "[744 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#1.- En el notebook 3_nb_***.ipynb, cargue los dos archivos d2019.csv y d2020.txt en dos\n",
    "#dataframes llamados df2019 y df2020 respectivamente. Luego, usando el método melt, \n",
    "#genera un dataframe llamado df_sii donde estén incluidos los datos del 2019 y del 2020,\n",
    "#que tenga las columnas year,mes, dia, valor, y guardalo como csv en la carpeta\n",
    "#data/interim con el nombre df_sii.csv.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df2019 = pd.read_csv('../data/interim/d2019.csv',index_col = 0,delimiter=\",\")\n",
    "df2020 = pd.read_csv('../data/interim/d2020.txt',index_col = 0,delimiter=\" \")\n",
    "\n",
    "df_concat_0 = pd.concat([df2019,df2020],axis=0)\n",
    "df_concat_0.reset_index(inplace=True)\n",
    "\n",
    "#print(df_concat_0)\n",
    "\n",
    "df_sii = pd.melt(df_concat_0,id_vars=['year','Día'],\n",
    "value_vars=['Ene', 'Feb','Mar','Abr','May','Jun','Jul','Ago','Sep','Oct','Nov','Dic'],\n",
    "var_name='Mes', value_name='valor')\n",
    "\n",
    "print(df_sii)\n",
    "\n",
    "df_sii.to_csv('../data/interim/df_sii.csv',sep =\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "d6663ed7fd234989b84dab3e63ed45bc",
    "deepnote_cell_height": 207,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1663212879214,
    "source_hash": "ea8a310d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#2.-Usando el método groupby en df_sii:\n",
    "\n",
    "#Agrupa por mes, con el argumento as_index = True y usando el método aggregation con el\n",
    "#método mean, imprime el resultado.\n",
    "#Agrupa por [year, mes], con el argumento as_index = False y usando el método agg con el\n",
    "#método mean, imprime el resultado\n",
    "#Compara ambos resultados. ¿Qué cambia al usar as_index = False? ¿Al agrupar por mes,\n",
    "# con respecto a [year,mes]?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "54a34d7e91ef4c959f045e781a71562d",
    "deepnote_cell_height": 1331,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 27,
    "execution_start": 1663212879215,
    "source_hash": "686bdadf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          valor\n",
      "Mes            \n",
      "Feb  468.607742\n",
      "Sep  470.538871\n",
      "Dic  485.523710\n",
      "May  486.231935\n",
      "Jun  492.197742\n",
      "Ago  507.510806\n",
      "Nov  508.890000\n",
      "Ene  514.413065\n",
      "Abr  515.102258\n",
      "Jul  521.892742\n",
      "Oct  522.843871\n",
      "Mar  523.992097\n",
      "    year  Mes       valor\n",
      "0   2019  Abr  452.109032\n",
      "10  2019  Oct  511.700323\n",
      "9   2019  Nov  500.987097\n",
      "8   2019  May  468.776774\n",
      "7   2019  Mar  452.298387\n",
      "6   2019  Jun  446.715484\n",
      "11  2019  Sep  417.160000\n",
      "4   2019  Feb  423.422258\n",
      "3   2019  Ene  480.495484\n",
      "2   2019  Dic  497.026129\n",
      "1   2019  Ago  483.476452\n",
      "5   2019  Jul  486.880968\n",
      "21  2020  Nov  516.792903\n",
      "20  2020  May  503.687097\n",
      "19  2020  Mar  595.685806\n",
      "18  2020  Jun  537.680000\n",
      "17  2020  Jul  556.904516\n",
      "15  2020  Ene  548.330645\n",
      "14  2020  Dic  474.021290\n",
      "13  2020  Ago  531.545161\n",
      "12  2020  Abr  578.095484\n",
      "22  2020  Oct  533.987419\n",
      "16  2020  Feb  513.793226\n",
      "23  2020  Sep  523.917742\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "#Agrupa por mes, con el argumento as_index = True y usando el método aggregation con el\n",
    "#método mean, imprime el resultado.\n",
    "\n",
    "print(df_sii.groupby('Mes', as_index=True).agg({\"valor\": \"mean\"}).sort_values(by = \"valor\")) \n",
    "\n",
    " \n",
    "#Agrupa por [year, mes], con el argumento as_index = False y usando el método agg con el\n",
    "#método mean, imprime el resultado\n",
    "\n",
    "print(df_sii.groupby(['year', 'Mes'], as_index=False).agg({\"valor\": \"mean\"}).sort_values(by = \"year\"))\n",
    "\n",
    "\n",
    "#Compara ambos resultados. ¿Qué cambia al usar as_index = False? ¿Al agrupar por mes,\n",
    "\n",
    "# con respecto a [year,mes]?\n",
    "\n",
    "#Al agrupar por mes con \"as_index\" =True, se retorna la etiqueta de la variable por la\n",
    "#cual se realiza la agrupación, es  este caso \"Mes\",  como índice de los resultados del\n",
    "#dataframe.\n",
    "\n",
    "#Al agrupar por [year, mes] con \"as_index\" =False, se retorna los índices  del\n",
    "#dataframe \"df_sii\"  de acuerdo a las filas de resultados obtenidos realizada\n",
    "#la agrupación por las variables  [year,mes]. La variables de la agrupación se \n",
    "#visualizan como columnas de resultados.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "c400d96ee7b74c92abf45f72fc801100",
    "deepnote_cell_height": 1931,
    "deepnote_cell_type": "code",
    "deepnote_table_loading": false,
    "deepnote_table_state": {
     "filters": [],
     "pageIndex": 9,
     "pageSize": 10,
     "sortBy": []
    },
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 114,
    "execution_start": 1663212879249,
    "source_hash": "2af865dd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year  Día  Mes  valor day_str month_str year_str   date_str       Date  \\\n",
      "63   2019    2  Feb    0.0      02        02      Feb  Feb-02-02 2002-02-02   \n",
      "64   2019    3  Feb    0.0      03        02      Feb  Feb-02-03 2003-02-02   \n",
      "70   2019    9  Feb    0.0      09        02      Feb  Feb-02-09 2009-02-02   \n",
      "71   2019   10  Feb    0.0      10        02      Feb  Feb-02-10 2010-02-02   \n",
      "77   2019   16  Feb    0.0      16        02      Feb  Feb-02-16 2016-02-02   \n",
      "78   2019   17  Feb    0.0      17        02      Feb  Feb-02-17 2017-02-02   \n",
      "84   2019   23  Feb    0.0      23        02      Feb  Feb-02-23 2023-02-02   \n",
      "85   2019   24  Feb    0.0      24        02      Feb  Feb-02-24 2024-02-02   \n",
      "90   2019   29  Feb    0.0      29        02      Feb  Feb-02-29 2029-02-02   \n",
      "91   2019   30  Feb    0.0      30        02      Feb  Feb-02-30 2030-02-02   \n",
      "92   2019   31  Feb    0.0      31        02      Feb  Feb-02-31 2031-02-02   \n",
      "93   2020    1  Feb    0.0      01        02      Feb  Feb-02-01 2001-02-02   \n",
      "94   2020    2  Feb    0.0      02        02      Feb  Feb-02-02 2002-02-02   \n",
      "100  2020    8  Feb    0.0      08        02      Feb  Feb-02-08 2008-02-02   \n",
      "101  2020    9  Feb    0.0      09        02      Feb  Feb-02-09 2009-02-02   \n",
      "107  2020   15  Feb    0.0      15        02      Feb  Feb-02-15 2015-02-02   \n",
      "108  2020   16  Feb    0.0      16        02      Feb  Feb-02-16 2016-02-02   \n",
      "114  2020   22  Feb    0.0      22        02      Feb  Feb-02-22 2022-02-02   \n",
      "115  2020   23  Feb    0.0      23        02      Feb  Feb-02-23 2023-02-02   \n",
      "121  2020   29  Feb    0.0      29        02      Feb  Feb-02-29 2029-02-02   \n",
      "122  2020   30  Feb    0.0      30        02      Feb  Feb-02-30 2030-02-02   \n",
      "123  2020   31  Feb    0.0      31        02      Feb  Feb-02-31 2031-02-02   \n",
      "125  2019    2  Mar    0.0      02        03      Mar  Mar-03-02 2002-03-03   \n",
      "126  2019    3  Mar    0.0      03        03      Mar  Mar-03-03 2003-03-03   \n",
      "132  2019    9  Mar    0.0      09        03      Mar  Mar-03-09 2009-03-03   \n",
      "133  2019   10  Mar    0.0      10        03      Mar  Mar-03-10 2010-03-03   \n",
      "139  2019   16  Mar    0.0      16        03      Mar  Mar-03-16 2016-03-03   \n",
      "140  2019   17  Mar    0.0      17        03      Mar  Mar-03-17 2017-03-03   \n",
      "146  2019   23  Mar    0.0      23        03      Mar  Mar-03-23 2023-03-03   \n",
      "147  2019   24  Mar    0.0      24        03      Mar  Mar-03-24 2024-03-03   \n",
      "153  2019   30  Mar    0.0      30        03      Mar  Mar-03-30 2030-03-03   \n",
      "154  2019   31  Mar    0.0      31        03      Mar  Mar-03-31 2031-03-03   \n",
      "155  2020    1  Mar    0.0      01        03      Mar  Mar-03-01 2001-03-03   \n",
      "161  2020    7  Mar    0.0      07        03      Mar  Mar-03-07 2007-03-03   \n",
      "162  2020    8  Mar    0.0      08        03      Mar  Mar-03-08 2008-03-03   \n",
      "168  2020   14  Mar    0.0      14        03      Mar  Mar-03-14 2014-03-03   \n",
      "169  2020   15  Mar    0.0      15        03      Mar  Mar-03-15 2015-03-03   \n",
      "175  2020   21  Mar    0.0      21        03      Mar  Mar-03-21 2021-03-03   \n",
      "176  2020   22  Mar    0.0      22        03      Mar  Mar-03-22 2022-03-03   \n",
      "182  2020   28  Mar    0.0      28        03      Mar  Mar-03-28 2028-03-03   \n",
      "183  2020   29  Mar    0.0      29        03      Mar  Mar-03-29 2029-03-03   \n",
      "248  2019    1  May    0.0      01        05      May  May-05-01 2001-05-05   \n",
      "251  2019    4  May    0.0      04        05      May  May-05-04 2004-05-05   \n",
      "252  2019    5  May    0.0      05        05      May  May-05-05 2005-05-05   \n",
      "258  2019   11  May    0.0      11        05      May  May-05-11 2011-05-05   \n",
      "259  2019   12  May    0.0      12        05      May  May-05-12 2012-05-05   \n",
      "265  2019   18  May    0.0      18        05      May  May-05-18 2018-05-05   \n",
      "266  2019   19  May    0.0      19        05      May  May-05-19 2019-05-05   \n",
      "268  2019   21  May    0.0      21        05      May  May-05-21 2021-05-05   \n",
      "272  2019   25  May    0.0      25        05      May  May-05-25 2025-05-05   \n",
      "273  2019   26  May    0.0      26        05      May  May-05-26 2026-05-05   \n",
      "279  2020    1  May    0.0      01        05      May  May-05-01 2001-05-05   \n",
      "280  2020    2  May    0.0      02        05      May  May-05-02 2002-05-05   \n",
      "281  2020    3  May    0.0      03        05      May  May-05-03 2003-05-05   \n",
      "287  2020    9  May    0.0      09        05      May  May-05-09 2009-05-05   \n",
      "288  2020   10  May    0.0      10        05      May  May-05-10 2010-05-05   \n",
      "294  2020   16  May    0.0      16        05      May  May-05-16 2016-05-05   \n",
      "295  2020   17  May    0.0      17        05      May  May-05-17 2017-05-05   \n",
      "299  2020   21  May    0.0      21        05      May  May-05-21 2021-05-05   \n",
      "301  2020   23  May    0.0      23        05      May  May-05-23 2023-05-05   \n",
      "302  2020   24  May    0.0      24        05      May  May-05-24 2024-05-05   \n",
      "308  2020   30  May    0.0      30        05      May  May-05-30 2030-05-05   \n",
      "309  2020   31  May    0.0      31        05      May  May-05-31 2031-05-05   \n",
      "310  2019    1  Jun    0.0      01        06      Jun  Jun-06-01 2001-06-06   \n",
      "311  2019    2  Jun    0.0      02        06      Jun  Jun-06-02 2002-06-06   \n",
      "317  2019    8  Jun    0.0      08        06      Jun  Jun-06-08 2008-06-06   \n",
      "318  2019    9  Jun    0.0      09        06      Jun  Jun-06-09 2009-06-06   \n",
      "324  2019   15  Jun    0.0      15        06      Jun  Jun-06-15 2015-06-06   \n",
      "325  2019   16  Jun    0.0      16        06      Jun  Jun-06-16 2016-06-06   \n",
      "331  2019   22  Jun    0.0      22        06      Jun  Jun-06-22 2022-06-06   \n",
      "332  2019   23  Jun    0.0      23        06      Jun  Jun-06-23 2023-06-06   \n",
      "338  2019   29  Jun    0.0      29        06      Jun  Jun-06-29 2029-06-06   \n",
      "339  2019   30  Jun    0.0      30        06      Jun  Jun-06-30 2030-06-06   \n",
      "340  2019   31  Jun    0.0      31        06      Jun  Jun-06-31 2031-06-06   \n",
      "346  2020    6  Jun    0.0      06        06      Jun  Jun-06-06 2006-06-06   \n",
      "347  2020    7  Jun    0.0      07        06      Jun  Jun-06-07 2007-06-06   \n",
      "353  2020   13  Jun    0.0      13        06      Jun  Jun-06-13 2013-06-06   \n",
      "354  2020   14  Jun    0.0      14        06      Jun  Jun-06-14 2014-06-06   \n",
      "360  2020   20  Jun    0.0      20        06      Jun  Jun-06-20 2020-06-06   \n",
      "361  2020   21  Jun    0.0      21        06      Jun  Jun-06-21 2021-06-06   \n",
      "367  2020   27  Jun    0.0      27        06      Jun  Jun-06-27 2027-06-06   \n",
      "368  2020   28  Jun    0.0      28        06      Jun  Jun-06-28 2028-06-06   \n",
      "369  2020   29  Jun    0.0      29        06      Jun  Jun-06-29 2029-06-06   \n",
      "371  2020   31  Jun    0.0      31        06      Jun  Jun-06-31 2031-06-06   \n",
      "377  2019    6  Jul    0.0      06        07      Jul  Jul-07-06 2006-07-07   \n",
      "378  2019    7  Jul    0.0      07        07      Jul  Jul-07-07 2007-07-07   \n",
      "384  2019   13  Jul    0.0      13        07      Jul  Jul-07-13 2013-07-07   \n",
      "385  2019   14  Jul    0.0      14        07      Jul  Jul-07-14 2014-07-07   \n",
      "387  2019   16  Jul    0.0      16        07      Jul  Jul-07-16 2016-07-07   \n",
      "391  2019   20  Jul    0.0      20        07      Jul  Jul-07-20 2020-07-07   \n",
      "392  2019   21  Jul    0.0      21        07      Jul  Jul-07-21 2021-07-07   \n",
      "398  2019   27  Jul    0.0      27        07      Jul  Jul-07-27 2027-07-07   \n",
      "399  2019   28  Jul    0.0      28        07      Jul  Jul-07-28 2028-07-07   \n",
      "406  2020    4  Jul    0.0      04        07      Jul  Jul-07-04 2004-07-07   \n",
      "407  2020    5  Jul    0.0      05        07      Jul  Jul-07-05 2005-07-07   \n",
      "413  2020   11  Jul    0.0      11        07      Jul  Jul-07-11 2011-07-07   \n",
      "414  2020   12  Jul    0.0      12        07      Jul  Jul-07-12 2012-07-07   \n",
      "418  2020   16  Jul    0.0      16        07      Jul  Jul-07-16 2016-07-07   \n",
      "420  2020   18  Jul    0.0      18        07      Jul  Jul-07-18 2018-07-07   \n",
      "421  2020   19  Jul    0.0      19        07      Jul  Jul-07-19 2019-07-07   \n",
      "427  2020   25  Jul    0.0      25        07      Jul  Jul-07-25 2025-07-07   \n",
      "428  2020   26  Jul    0.0      26        07      Jul  Jul-07-26 2026-07-07   \n",
      "496  2019    1  Sep    0.0      01        09      Sep  Sep-09-01 2001-09-09   \n",
      "502  2019    7  Sep    0.0      07        09      Sep  Sep-09-07 2007-09-09   \n",
      "503  2019    8  Sep    0.0      08        09      Sep  Sep-09-08 2008-09-09   \n",
      "509  2019   14  Sep    0.0      14        09      Sep  Sep-09-14 2014-09-09   \n",
      "510  2019   15  Sep    0.0      15        09      Sep  Sep-09-15 2015-09-09   \n",
      "513  2019   18  Sep    0.0      18        09      Sep  Sep-09-18 2018-09-09   \n",
      "514  2019   19  Sep    0.0      19        09      Sep  Sep-09-19 2019-09-09   \n",
      "515  2019   20  Sep    0.0      20        09      Sep  Sep-09-20 2020-09-09   \n",
      "516  2019   21  Sep    0.0      21        09      Sep  Sep-09-21 2021-09-09   \n",
      "517  2019   22  Sep    0.0      22        09      Sep  Sep-09-22 2022-09-09   \n",
      "523  2019   28  Sep    0.0      28        09      Sep  Sep-09-28 2028-09-09   \n",
      "524  2019   29  Sep    0.0      29        09      Sep  Sep-09-29 2029-09-09   \n",
      "526  2019   31  Sep    0.0      31        09      Sep  Sep-09-31 2031-09-09   \n",
      "531  2020    5  Sep    0.0      05        09      Sep  Sep-09-05 2005-09-09   \n",
      "532  2020    6  Sep    0.0      06        09      Sep  Sep-09-06 2006-09-09   \n",
      "538  2020   12  Sep    0.0      12        09      Sep  Sep-09-12 2012-09-09   \n",
      "539  2020   13  Sep    0.0      13        09      Sep  Sep-09-13 2013-09-09   \n",
      "544  2020   18  Sep    0.0      18        09      Sep  Sep-09-18 2018-09-09   \n",
      "545  2020   19  Sep    0.0      19        09      Sep  Sep-09-19 2019-09-09   \n",
      "546  2020   20  Sep    0.0      20        09      Sep  Sep-09-20 2020-09-09   \n",
      "552  2020   26  Sep    0.0      26        09      Sep  Sep-09-26 2026-09-09   \n",
      "553  2020   27  Sep    0.0      27        09      Sep  Sep-09-27 2027-09-09   \n",
      "557  2020   31  Sep    0.0      31        09      Sep  Sep-09-31 2031-09-09   \n",
      "562  2019    5  Oct    0.0      05        10      Oct  Oct-10-05 2005-10-10   \n",
      "563  2019    6  Oct    0.0      06        10      Oct  Oct-10-06 2006-10-10   \n",
      "569  2019   12  Oct    0.0      12        10      Oct  Oct-10-12 2012-10-10   \n",
      "570  2019   13  Oct    0.0      13        10      Oct  Oct-10-13 2013-10-10   \n",
      "576  2019   19  Oct    0.0      19        10      Oct  Oct-10-19 2019-10-10   \n",
      "577  2019   20  Oct    0.0      20        10      Oct  Oct-10-20 2020-10-10   \n",
      "583  2019   26  Oct    0.0      26        10      Oct  Oct-10-26 2026-10-10   \n",
      "584  2019   27  Oct    0.0      27        10      Oct  Oct-10-27 2027-10-10   \n",
      "588  2019   31  Oct    0.0      31        10      Oct  Oct-10-31 2031-10-10   \n",
      "591  2020    3  Oct    0.0      03        10      Oct  Oct-10-03 2003-10-10   \n",
      "592  2020    4  Oct    0.0      04        10      Oct  Oct-10-04 2004-10-10   \n",
      "598  2020   10  Oct    0.0      10        10      Oct  Oct-10-10 2010-10-10   \n",
      "599  2020   11  Oct    0.0      11        10      Oct  Oct-10-11 2011-10-10   \n",
      "600  2020   12  Oct    0.0      12        10      Oct  Oct-10-12 2012-10-10   \n",
      "605  2020   17  Oct    0.0      17        10      Oct  Oct-10-17 2017-10-10   \n",
      "606  2020   18  Oct    0.0      18        10      Oct  Oct-10-18 2018-10-10   \n",
      "612  2020   24  Oct    0.0      24        10      Oct  Oct-10-24 2024-10-10   \n",
      "613  2020   25  Oct    0.0      25        10      Oct  Oct-10-25 2025-10-10   \n",
      "619  2020   31  Oct    0.0      31        10      Oct  Oct-10-31 2031-10-10   \n",
      "620  2019    1  Nov    0.0      01        11      Nov  Nov-11-01 2001-11-11   \n",
      "621  2019    2  Nov    0.0      02        11      Nov  Nov-11-02 2002-11-11   \n",
      "622  2019    3  Nov    0.0      03        11      Nov  Nov-11-03 2003-11-11   \n",
      "628  2019    9  Nov    0.0      09        11      Nov  Nov-11-09 2009-11-11   \n",
      "629  2019   10  Nov    0.0      10        11      Nov  Nov-11-10 2010-11-11   \n",
      "635  2019   16  Nov    0.0      16        11      Nov  Nov-11-16 2016-11-11   \n",
      "636  2019   17  Nov    0.0      17        11      Nov  Nov-11-17 2017-11-11   \n",
      "642  2019   23  Nov    0.0      23        11      Nov  Nov-11-23 2023-11-11   \n",
      "643  2019   24  Nov    0.0      24        11      Nov  Nov-11-24 2024-11-11   \n",
      "649  2019   30  Nov    0.0      30        11      Nov  Nov-11-30 2030-11-11   \n",
      "650  2019   31  Nov    0.0      31        11      Nov  Nov-11-31 2031-11-11   \n",
      "651  2020    1  Nov    0.0      01        11      Nov  Nov-11-01 2001-11-11   \n",
      "657  2020    7  Nov    0.0      07        11      Nov  Nov-11-07 2007-11-11   \n",
      "658  2020    8  Nov    0.0      08        11      Nov  Nov-11-08 2008-11-11   \n",
      "664  2020   14  Nov    0.0      14        11      Nov  Nov-11-14 2014-11-11   \n",
      "665  2020   15  Nov    0.0      15        11      Nov  Nov-11-15 2015-11-11   \n",
      "671  2020   21  Nov    0.0      21        11      Nov  Nov-11-21 2021-11-11   \n",
      "672  2020   22  Nov    0.0      22        11      Nov  Nov-11-22 2022-11-11   \n",
      "678  2020   28  Nov    0.0      28        11      Nov  Nov-11-28 2028-11-11   \n",
      "679  2020   29  Nov    0.0      29        11      Nov  Nov-11-29 2029-11-11   \n",
      "681  2020   31  Nov    0.0      31        11      Nov  Nov-11-31 2031-11-11   \n",
      "\n",
      "    dia_de_la_semana  \n",
      "63            Sabado  \n",
      "64           Domingo  \n",
      "70             Lunes  \n",
      "71            Martes  \n",
      "77            Martes  \n",
      "78            Jueves  \n",
      "84            Jueves  \n",
      "85           Viernes  \n",
      "90           Viernes  \n",
      "91            Sabado  \n",
      "92           Domingo  \n",
      "93           Viernes  \n",
      "94            Sabado  \n",
      "100           Sabado  \n",
      "101            Lunes  \n",
      "107            Lunes  \n",
      "108           Martes  \n",
      "114        Miercoles  \n",
      "115           Jueves  \n",
      "121          Viernes  \n",
      "122           Sabado  \n",
      "123          Domingo  \n",
      "125          Domingo  \n",
      "126            Lunes  \n",
      "132           Martes  \n",
      "133        Miercoles  \n",
      "139           Jueves  \n",
      "140          Viernes  \n",
      "146          Viernes  \n",
      "147          Domingo  \n",
      "153          Domingo  \n",
      "154            Lunes  \n",
      "155           Sabado  \n",
      "161           Sabado  \n",
      "162            Lunes  \n",
      "168            Lunes  \n",
      "169           Martes  \n",
      "175        Miercoles  \n",
      "176           Jueves  \n",
      "182          Viernes  \n",
      "183           Sabado  \n",
      "248           Sabado  \n",
      "251        Miercoles  \n",
      "252           Jueves  \n",
      "258           Jueves  \n",
      "259           Sabado  \n",
      "265           Sabado  \n",
      "266          Domingo  \n",
      "268        Miercoles  \n",
      "272            Lunes  \n",
      "273           Martes  \n",
      "279           Sabado  \n",
      "280          Domingo  \n",
      "281            Lunes  \n",
      "287           Martes  \n",
      "288        Miercoles  \n",
      "294           Jueves  \n",
      "295          Viernes  \n",
      "299        Miercoles  \n",
      "301          Viernes  \n",
      "302          Domingo  \n",
      "308          Domingo  \n",
      "309            Lunes  \n",
      "310        Miercoles  \n",
      "311           Jueves  \n",
      "317          Viernes  \n",
      "318           Sabado  \n",
      "324           Sabado  \n",
      "325            Lunes  \n",
      "331            Lunes  \n",
      "332           Martes  \n",
      "338        Miercoles  \n",
      "339           Jueves  \n",
      "340          Viernes  \n",
      "346           Martes  \n",
      "347        Miercoles  \n",
      "353           Jueves  \n",
      "354          Viernes  \n",
      "360           Sabado  \n",
      "361          Domingo  \n",
      "367          Domingo  \n",
      "368           Martes  \n",
      "369        Miercoles  \n",
      "371          Viernes  \n",
      "377          Viernes  \n",
      "378           Sabado  \n",
      "384          Domingo  \n",
      "385            Lunes  \n",
      "387           Jueves  \n",
      "391           Martes  \n",
      "392        Miercoles  \n",
      "398        Miercoles  \n",
      "399          Viernes  \n",
      "406        Miercoles  \n",
      "407           Jueves  \n",
      "413           Jueves  \n",
      "414           Sabado  \n",
      "418           Jueves  \n",
      "420           Sabado  \n",
      "421          Domingo  \n",
      "427            Lunes  \n",
      "428           Martes  \n",
      "496          Domingo  \n",
      "502          Domingo  \n",
      "503           Martes  \n",
      "509           Martes  \n",
      "510        Miercoles  \n",
      "513          Domingo  \n",
      "514            Lunes  \n",
      "515        Miercoles  \n",
      "516           Jueves  \n",
      "517          Viernes  \n",
      "523           Sabado  \n",
      "524          Domingo  \n",
      "526           Martes  \n",
      "531          Viernes  \n",
      "532           Sabado  \n",
      "538          Domingo  \n",
      "539            Lunes  \n",
      "544          Domingo  \n",
      "545            Lunes  \n",
      "546        Miercoles  \n",
      "552        Miercoles  \n",
      "553           Jueves  \n",
      "557           Martes  \n",
      "562            Lunes  \n",
      "563           Martes  \n",
      "569        Miercoles  \n",
      "570           Jueves  \n",
      "576           Jueves  \n",
      "577           Sabado  \n",
      "583           Sabado  \n",
      "584          Domingo  \n",
      "588          Viernes  \n",
      "591          Viernes  \n",
      "592          Domingo  \n",
      "598          Domingo  \n",
      "599            Lunes  \n",
      "600        Miercoles  \n",
      "605           Martes  \n",
      "606        Miercoles  \n",
      "612           Jueves  \n",
      "613          Viernes  \n",
      "619          Viernes  \n",
      "620          Domingo  \n",
      "621            Lunes  \n",
      "622           Martes  \n",
      "628        Miercoles  \n",
      "629           Jueves  \n",
      "635          Viernes  \n",
      "636           Sabado  \n",
      "642           Sabado  \n",
      "643            Lunes  \n",
      "649            Lunes  \n",
      "650           Martes  \n",
      "651          Domingo  \n",
      "657          Domingo  \n",
      "658           Martes  \n",
      "664           Martes  \n",
      "665        Miercoles  \n",
      "671           Jueves  \n",
      "672          Viernes  \n",
      "678           Sabado  \n",
      "679          Domingo  \n",
      "681           Martes  \n"
     ]
    }
   ],
   "source": [
    "#3.-¿Qué podrías inferir de los missing values y los días hábiles? Úsalos para crear una nueva variable\n",
    "#llamada dia_de_la_semana en df_sii con valores \"Lunes\", \"Martes\", \"Miércoles\", \"Jueves\",\n",
    "#\"Viernes\", \"Sábado\", \"Domingo\".\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df_sii[\"day_str\"] = df_sii[\"Día\"].astype(str)\n",
    "df_sii[\"day_str\"] = df_sii[\"day_str\"].str.pad(2,side='left',fillchar='0')\n",
    "\n",
    "df_sii[\"month_str\"] = np.where(df_sii['Mes']=='Ene', '01',\n",
    "              np.where(df_sii['Mes']=='Feb', '02',\n",
    "              np.where(df_sii['Mes']=='Mar', '03',\n",
    "              np.where(df_sii['Mes']=='Abr', '04',\n",
    "              np.where(df_sii['Mes']=='May', '05',\n",
    "              np.where(df_sii['Mes']=='Jun', '06',\n",
    "              np.where(df_sii['Mes']=='Jul', '07',\n",
    "              np.where(df_sii['Mes']=='Ago', '08',\n",
    "              np.where(df_sii['Mes']=='Sep', '09',\n",
    "              np.where(df_sii['Mes']=='Oct', '10',\n",
    "              np.where(df_sii['Mes']=='Nov', '11',\n",
    "              np.where(df_sii['Mes']=='Dic', '12', 'Ene'))))))))))))\n",
    "df_sii[\"year_str\"] = df_sii[\"Mes\"].astype(str)\n",
    "df_sii[\"date_str\"] = df_sii[\"year_str\"]+\"-\"+df_sii[\"month_str\"]+\"-\"+df_sii[\"day_str\"]\n",
    "df_sii['Date'] = pd.to_datetime(df_sii['date_str'], errors='coerce')\n",
    "#df_sii['Date'] = df['Date'].apply(pd.datetools.normalize_date)\n",
    "\n",
    "pd.set_option('max_rows', 300)\n",
    "#print(df_sii.Date.dtype)\n",
    "#df_sii[\"dia_de_la_semana\"] =  df_sii['Date'].dt.dayofweek\n",
    "def my_func(row):\n",
    "    return row.dayofweek\n",
    "df_sii[\"dia_de_la_semana\"] =  df_sii['Date'].apply(lambda x: my_func(x) if(pd.notnull(x)) else -1)\n",
    "df_sii[\"dia_de_la_semana\"] = np.where(df_sii['dia_de_la_semana']==0, 'Lunes',\n",
    "              np.where(df_sii['dia_de_la_semana']==1, 'Martes',\n",
    "              np.where(df_sii['dia_de_la_semana']==2, 'Miercoles',\n",
    "              np.where(df_sii['dia_de_la_semana']==3, 'Jueves',\n",
    "              np.where(df_sii['dia_de_la_semana']==4, 'Viernes',\n",
    "              np.where(df_sii['dia_de_la_semana']==5, 'Sabado',\n",
    "              np.where(df_sii['dia_de_la_semana']==6, 'Domingo', 'NA')))))))\n",
    "#df[['A','B']].apply(lambda x: my_func(x) if(pd.notnull(x[0])) else x, axis = 1)\n",
    "#df_sii['Date'].dt.day_of_week\n",
    "df_sii\n",
    "\n",
    "df_sii = df_sii[df_sii['dia_de_la_semana'] != 'NA'] \n",
    "#acá se sacan los NA que corresponden a los días que no existen ej el 31 de febrero\n",
    "df_sii\n",
    "df_sii2=df_sii[df_sii['valor']==0] \n",
    "# acá mostramos los valores 0 (anteriormente habiamos reemplazado los nan por cero)\n",
    "#y justamente corresponde a sabado y domingo más días festivos\n",
    "\n",
    "\n",
    "#Por lo tanto, en la base el valor 0.0 correspondiente al dolar, no signfica que el dolar haya estado a 0 pesos.\n",
    "#Significa que ese día el mercado estaba cerrado\n",
    "\n",
    "print(df_sii2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "d9e60eeb6e9c4034a3d645be55e668af",
    "deepnote_cell_height": 212.75,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2435,
    "execution_start": 1663212879361,
    "source_hash": "ea22c22c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\zine5\\anaconda3\\lib\\site-packages (3.0.7)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\zine5\\anaconda3\\lib\\site-packages (from openpyxl) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "2f734270d8cb48a1a629a9ee404b01f4",
    "deepnote_cell_height": 1985,
    "deepnote_cell_type": "code",
    "deepnote_table_loading": false,
    "deepnote_table_state": {
     "filters": [],
     "pageIndex": 0,
     "pageSize": 10,
     "sortBy": []
    },
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 994,
    "execution_start": 1663212881324,
    "source_hash": "95c3afb9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Periodo</th>\n",
       "      <th>1.Dólar observado</th>\n",
       "      <th>year</th>\n",
       "      <th>mes</th>\n",
       "      <th>dia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13294</th>\n",
       "      <td>3287</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13295</th>\n",
       "      <td>3288</td>\n",
       "      <td>2019-01-02 00:00:00</td>\n",
       "      <td>694.77</td>\n",
       "      <td>2019</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13296</th>\n",
       "      <td>3289</td>\n",
       "      <td>2019-01-03 00:00:00</td>\n",
       "      <td>697.09</td>\n",
       "      <td>2019</td>\n",
       "      <td>01</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13297</th>\n",
       "      <td>3290</td>\n",
       "      <td>2019-01-04 00:00:00</td>\n",
       "      <td>697.64</td>\n",
       "      <td>2019</td>\n",
       "      <td>01</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13298</th>\n",
       "      <td>3291</td>\n",
       "      <td>2019-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>01</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14020</th>\n",
       "      <td>361</td>\n",
       "      <td>2020-12-27 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14021</th>\n",
       "      <td>362</td>\n",
       "      <td>2020-12-28 00:00:00</td>\n",
       "      <td>710.26</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14022</th>\n",
       "      <td>363</td>\n",
       "      <td>2020-12-29 00:00:00</td>\n",
       "      <td>710.64</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023</th>\n",
       "      <td>364</td>\n",
       "      <td>2020-12-30 00:00:00</td>\n",
       "      <td>711.24</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14024</th>\n",
       "      <td>365</td>\n",
       "      <td>2020-12-31 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index              Periodo  1.Dólar observado  year mes dia\n",
       "13294   3287  2019-01-01 00:00:00                NaN  2019  01  01\n",
       "13295   3288  2019-01-02 00:00:00             694.77  2019  01  02\n",
       "13296   3289  2019-01-03 00:00:00             697.09  2019  01  03\n",
       "13297   3290  2019-01-04 00:00:00             697.64  2019  01  04\n",
       "13298   3291  2019-01-05 00:00:00                NaN  2019  01  05\n",
       "...      ...                  ...                ...   ...  ..  ..\n",
       "14020    361  2020-12-27 00:00:00                NaN  2020  12  27\n",
       "14021    362  2020-12-28 00:00:00             710.26  2020  12  28\n",
       "14022    363  2020-12-29 00:00:00             710.64  2020  12  29\n",
       "14023    364  2020-12-30 00:00:00             711.24  2020  12  30\n",
       "14024    365  2020-12-31 00:00:00                NaN  2020  12  31\n",
       "\n",
       "[731 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4.-Explora el archivo dolar_observado_bc.xlsx y su estructura.  \n",
    "\n",
    "#Lee cada hoja por separado con read_excel, usando los argumentos skiprows=2, dtype={'Periodo':str }.\n",
    "#Ocupa el método str.split para crear las columnas dia,mes y year en cada dataframe.\n",
    "#Crea un dataframe que una todos los dataframes en uno solo con las mismas columnas, y nombralo df_bc_all.\n",
    "#Crea una carpeta dentro de la carpeta data/processed llamada dolar_bc_year, agrupa por year usando groupby\n",
    "#y guarda un CSV para cada año desde 1982 hasta 2022, con los nombres dolar_bc_YYYY.csv donde YYYY es el\n",
    "#año. Busca una manera de hacerlo iterando y no uno a uno.\n",
    "#Crea un dataframe que tenga los años 2019 y 2020 que se llame df_bc_2019_2020\n",
    "#Compara los valores de df_bc_2019_2020 y df_sii. ¿Son iguales o diferentes?\n",
    "\n",
    "\n",
    "#4.1 Lee cada hoja por separado con read_excel, usando los argumentos skiprows=2, dtype={'Periodo':str }.\n",
    "\n",
    "#dolar_observado_bc=pd.read_excel('data/raw/dolar_observado_bc.xlsx',skiprows=2,dtype={'Periodo':str })\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    " \n",
    "dolar_observado_bc_80=pd.read_excel('../data/raw/dolar_observado_bc.xlsx',engine='openpyxl',skiprows=2,dtype={'Periodo':str },sheet_name='80')\n",
    "dolar_observado_bc_90=pd.read_excel('../data/raw/dolar_observado_bc.xlsx',engine='openpyxl',skiprows=2,dtype={'Periodo':str },sheet_name='90')\n",
    "dolar_observado_bc_00=pd.read_excel('../data/raw/dolar_observado_bc.xlsx',engine='openpyxl',skiprows=2,dtype={'Periodo':str },sheet_name='00')\n",
    "dolar_observado_bc_10=pd.read_excel('../data/raw/dolar_observado_bc.xlsx',engine='openpyxl',skiprows=2,dtype={'Periodo':str },sheet_name='10')\n",
    "dolar_observado_bc_20=pd.read_excel('../data/raw/dolar_observado_bc.xlsx',engine='openpyxl',skiprows=2,dtype={'Periodo':str },sheet_name='20')\n",
    "\n",
    "\n",
    "#4.2 Ocupa el método str.split para crear las columnas dia,mes y year en cada dataframe.\n",
    "\n",
    "dolar_observado_bc_80[['year','mes','dia']]=dolar_observado_bc_80.Periodo.str.split('-',expand=True)\n",
    "dolar_observado_bc_90[['year','mes','dia']]=dolar_observado_bc_90.Periodo.str.split('-',expand=True)\n",
    "dolar_observado_bc_00[['year','mes','dia']]=dolar_observado_bc_00.Periodo.str.split('-',expand=True)\n",
    "dolar_observado_bc_10[['year','mes','dia']]=dolar_observado_bc_10.Periodo.str.split('-',expand=True)\n",
    "dolar_observado_bc_20[['year','mes','dia']]=dolar_observado_bc_20.Periodo.str.split('-',expand=True)\n",
    " \n",
    "dolar_observado_bc_80['dia']=dolar_observado_bc_80.dia.str.split(' ').str[0]\n",
    "dolar_observado_bc_90['dia']=dolar_observado_bc_90.dia.str.split(' ').str[0]\n",
    "dolar_observado_bc_00['dia']=dolar_observado_bc_00.dia.str.split(' ').str[0]\n",
    "dolar_observado_bc_10['dia']=dolar_observado_bc_10.dia.str.split(' ').str[0]\n",
    "dolar_observado_bc_20['dia']=dolar_observado_bc_20.dia.str.split(' ').str[0]\n",
    "\n",
    "\n",
    "\n",
    "#4.3 Crea un dataframe que una todos los dataframes en uno solo con las mismas columnas, y nombralo df_bc_all.\n",
    "\n",
    "df_bc_all= pd.concat([dolar_observado_bc_80, dolar_observado_bc_90,dolar_observado_bc_00,dolar_observado_bc_10,dolar_observado_bc_20]).reset_index()\n",
    "         \n",
    "\n",
    "4.4  #Crea una carpeta dentro de la carpeta data/processed llamada dolar_bc_year, agrupa por year usando groupby\n",
    "#y guarda un CSV para cada año desde 1982 hasta 2022, con los nombres dolar_bc_YYYY.csv donde YYYY es el\n",
    "#año. Busca una manera de hacerlo iterando y no uno a uno.\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from os import mkdir\n",
    "if not os.path.exists('../data/processed/dolar_bc_year'):\n",
    "    os.makedirs('../data/processed/dolar_bc_year')\n",
    "\n",
    "df_bc_all['year']=df_bc_all['year'].astype('int')   \n",
    "      \n",
    "df_bc_agrupado = df_bc_all.groupby('year')\n",
    "\n",
    "for anio,gr  in df_bc_agrupado:\n",
    "    \n",
    "    gr.to_csv(f\"../data/processed/dolar_bc_year/dolar_bc_{anio}.csv\",sep =\",\")\n",
    "\n",
    "\n",
    "4.5 #Crea un dataframe que tenga los años 2019 y 2020 que se llame df_bc_2019_2020\n",
    "    #Compara los valores de df_bc_2019_2020 y df_sii. ¿Son iguales o diferentes?\n",
    "\n",
    "df_bc_2019_2020 = df_bc_all[(df_bc_all.year == 2019) | (df_bc_all.year == 2020)]\n",
    "df_bc_2019_2020\n",
    "\n",
    "#Ambos muestran la misma informacion(Año, mes, día, valor, periodo), sin embargo el dataframe df_sii\n",
    "#muestra las fechas en formato \"Date\" y en string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "cb72549a576c4e9f94cc38a7c2fc5420",
    "deepnote_cell_height": 612,
    "deepnote_cell_type": "code",
    "deepnote_table_loading": false,
    "deepnote_table_state": {
     "filters": [],
     "pageIndex": 69,
     "pageSize": 10,
     "sortBy": []
    },
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 27,
    "execution_start": 1663212882320,
    "source_hash": "f87db60d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Día</th>\n",
       "      <th>Mes</th>\n",
       "      <th>valor</th>\n",
       "      <th>day_str</th>\n",
       "      <th>month_str</th>\n",
       "      <th>year_str</th>\n",
       "      <th>date_str</th>\n",
       "      <th>Date</th>\n",
       "      <th>dia_de_la_semana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>Feb</td>\n",
       "      <td>657.81</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Feb-02-01</td>\n",
       "      <td>2001-02-02</td>\n",
       "      <td>Viernes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>Feb</td>\n",
       "      <td>0.00</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Feb-02-02</td>\n",
       "      <td>2002-02-02</td>\n",
       "      <td>Sabado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>Feb</td>\n",
       "      <td>0.00</td>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Feb-02-03</td>\n",
       "      <td>2003-02-02</td>\n",
       "      <td>Domingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>Feb</td>\n",
       "      <td>655.39</td>\n",
       "      <td>04</td>\n",
       "      <td>02</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Feb-02-04</td>\n",
       "      <td>2004-02-02</td>\n",
       "      <td>Lunes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>Feb</td>\n",
       "      <td>653.80</td>\n",
       "      <td>05</td>\n",
       "      <td>02</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Feb-02-05</td>\n",
       "      <td>2005-02-02</td>\n",
       "      <td>Miercoles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>2020</td>\n",
       "      <td>27</td>\n",
       "      <td>Nov</td>\n",
       "      <td>766.00</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>Nov</td>\n",
       "      <td>Nov-11-27</td>\n",
       "      <td>2027-11-11</td>\n",
       "      <td>Jueves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>2020</td>\n",
       "      <td>28</td>\n",
       "      <td>Nov</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>Nov</td>\n",
       "      <td>Nov-11-28</td>\n",
       "      <td>2028-11-11</td>\n",
       "      <td>Sabado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>2020</td>\n",
       "      <td>29</td>\n",
       "      <td>Nov</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>Nov</td>\n",
       "      <td>Nov-11-29</td>\n",
       "      <td>2029-11-11</td>\n",
       "      <td>Domingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>2020</td>\n",
       "      <td>30</td>\n",
       "      <td>Nov</td>\n",
       "      <td>766.69</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>Nov</td>\n",
       "      <td>Nov-11-30</td>\n",
       "      <td>2030-11-11</td>\n",
       "      <td>Lunes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>2020</td>\n",
       "      <td>31</td>\n",
       "      <td>Nov</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>Nov</td>\n",
       "      <td>Nov-11-31</td>\n",
       "      <td>2031-11-11</td>\n",
       "      <td>Martes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  Día  Mes   valor day_str month_str year_str   date_str       Date  \\\n",
       "62   2019    1  Feb  657.81      01        02      Feb  Feb-02-01 2001-02-02   \n",
       "63   2019    2  Feb    0.00      02        02      Feb  Feb-02-02 2002-02-02   \n",
       "64   2019    3  Feb    0.00      03        02      Feb  Feb-02-03 2003-02-02   \n",
       "65   2019    4  Feb  655.39      04        02      Feb  Feb-02-04 2004-02-02   \n",
       "66   2019    5  Feb  653.80      05        02      Feb  Feb-02-05 2005-02-02   \n",
       "..    ...  ...  ...     ...     ...       ...      ...        ...        ...   \n",
       "677  2020   27  Nov  766.00      27        11      Nov  Nov-11-27 2027-11-11   \n",
       "678  2020   28  Nov    0.00      28        11      Nov  Nov-11-28 2028-11-11   \n",
       "679  2020   29  Nov    0.00      29        11      Nov  Nov-11-29 2029-11-11   \n",
       "680  2020   30  Nov  766.69      30        11      Nov  Nov-11-30 2030-11-11   \n",
       "681  2020   31  Nov    0.00      31        11      Nov  Nov-11-31 2031-11-11   \n",
       "\n",
       "    dia_de_la_semana  \n",
       "62           Viernes  \n",
       "63            Sabado  \n",
       "64           Domingo  \n",
       "65             Lunes  \n",
       "66         Miercoles  \n",
       "..               ...  \n",
       "677           Jueves  \n",
       "678           Sabado  \n",
       "679          Domingo  \n",
       "680            Lunes  \n",
       "681           Martes  \n",
       "\n",
       "[496 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "f66b0d469608432b92f5b5cba93a23f0",
    "deepnote_cell_height": 4547,
    "deepnote_cell_type": "code",
    "deepnote_table_loading": false,
    "deepnote_table_state": {
     "filters": [],
     "pageIndex": 0,
     "pageSize": 100,
     "sortBy": [
      {
       "id": "date_str",
       "type": "desc"
      }
     ]
    },
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 129,
    "execution_start": 1663212882355,
    "source_hash": "f7c05955",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dia_de_la_semana_x</th>\n",
       "      <th>mes</th>\n",
       "      <th>date_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Sabado</td>\n",
       "      <td>08</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Domingo</td>\n",
       "      <td>08</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Domingo</td>\n",
       "      <td>01</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Domingo</td>\n",
       "      <td>07</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Sabado</td>\n",
       "      <td>10</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Domingo</td>\n",
       "      <td>05</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Sabado</td>\n",
       "      <td>03</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Sabado</td>\n",
       "      <td>01</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Domingo</td>\n",
       "      <td>03</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Domingo</td>\n",
       "      <td>10</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Domingo</td>\n",
       "      <td>12</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Sabado</td>\n",
       "      <td>12</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Sabado</td>\n",
       "      <td>07</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Sabado</td>\n",
       "      <td>05</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Sabado</td>\n",
       "      <td>04</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Sabado</td>\n",
       "      <td>06</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Domingo</td>\n",
       "      <td>09</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Sabado</td>\n",
       "      <td>11</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Sabado</td>\n",
       "      <td>09</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Domingo</td>\n",
       "      <td>11</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Domingo</td>\n",
       "      <td>06</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Domingo</td>\n",
       "      <td>04</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Sabado</td>\n",
       "      <td>02</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Domingo</td>\n",
       "      <td>02</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Viernes</td>\n",
       "      <td>04</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lunes</td>\n",
       "      <td>06</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Lunes</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lunes</td>\n",
       "      <td>09</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Jueves</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Viernes</td>\n",
       "      <td>09</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Martes</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Viernes</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Lunes</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Miercoles</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Miercoles</td>\n",
       "      <td>09</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jueves</td>\n",
       "      <td>05</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Martes</td>\n",
       "      <td>09</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Jueves</td>\n",
       "      <td>09</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Lunes</td>\n",
       "      <td>05</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Viernes</td>\n",
       "      <td>05</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jueves</td>\n",
       "      <td>06</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Martes</td>\n",
       "      <td>05</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Miercoles</td>\n",
       "      <td>05</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Viernes</td>\n",
       "      <td>03</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Viernes</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Lunes</td>\n",
       "      <td>08</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Viernes</td>\n",
       "      <td>01</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Lunes</td>\n",
       "      <td>07</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Martes</td>\n",
       "      <td>01</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lunes</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Martes</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lunes</td>\n",
       "      <td>01</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Jueves</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Miercoles</td>\n",
       "      <td>08</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Jueves</td>\n",
       "      <td>08</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Miercoles</td>\n",
       "      <td>01</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Miercoles</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Viernes</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jueves</td>\n",
       "      <td>01</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Viernes</td>\n",
       "      <td>08</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Martes</td>\n",
       "      <td>08</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Jueves</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Miercoles</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Miercoles</td>\n",
       "      <td>04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Martes</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Martes</td>\n",
       "      <td>06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Jueves</td>\n",
       "      <td>07</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Miercoles</td>\n",
       "      <td>06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Martes</td>\n",
       "      <td>07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Viernes</td>\n",
       "      <td>07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Miercoles</td>\n",
       "      <td>07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Viernes</td>\n",
       "      <td>06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lunes</td>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dia_de_la_semana_x mes  date_str\n",
       "57             Sabado  08       180\n",
       "7             Domingo  08       179\n",
       "0             Domingo  01       178\n",
       "6             Domingo  07       178\n",
       "59             Sabado  10       178\n",
       "4             Domingo  05       178\n",
       "52             Sabado  03       177\n",
       "50             Sabado  01       177\n",
       "2             Domingo  03       177\n",
       "9             Domingo  10       177\n",
       "11            Domingo  12       177\n",
       "61             Sabado  12       177\n",
       "56             Sabado  07       177\n",
       "54             Sabado  05       176\n",
       "53             Sabado  04       172\n",
       "55             Sabado  06       172\n",
       "8             Domingo  09       172\n",
       "60             Sabado  11       171\n",
       "58             Sabado  09       171\n",
       "10            Domingo  11       171\n",
       "5             Domingo  06       171\n",
       "3             Domingo  04       171\n",
       "51             Sabado  02       162\n",
       "1             Domingo  02       161\n",
       "64            Viernes  04        31\n",
       "24              Lunes  06        22\n",
       "28              Lunes  10        21\n",
       "27              Lunes  09        20\n",
       "20             Jueves  12        19\n",
       "69            Viernes  09        19\n",
       "39             Martes  12        18\n",
       "72            Viernes  12        17\n",
       "30              Lunes  12        16\n",
       "49          Miercoles  12        16\n",
       "46          Miercoles  09        15\n",
       "13             Jueves  05        14\n",
       "36             Martes  09        13\n",
       "17             Jueves  09        13\n",
       "23              Lunes  05        13\n",
       "65            Viernes  05        12\n",
       "14             Jueves  06        12\n",
       "32             Martes  05        12\n",
       "42          Miercoles  05        11\n",
       "63            Viernes  03        10\n",
       "71            Viernes  11         8\n",
       "26              Lunes  08         7\n",
       "62            Viernes  01         7\n",
       "25              Lunes  07         7\n",
       "31             Martes  01         6\n",
       "29              Lunes  11         6\n",
       "38             Martes  11         6\n",
       "21              Lunes  01         6\n",
       "19             Jueves  11         6\n",
       "45          Miercoles  08         6\n",
       "16             Jueves  08         6\n",
       "40          Miercoles  01         6\n",
       "48          Miercoles  11         5\n",
       "70            Viernes  10         5\n",
       "12             Jueves  01         5\n",
       "68            Viernes  08         5\n",
       "35             Martes  08         5\n",
       "18             Jueves  10         4\n",
       "47          Miercoles  10         4\n",
       "41          Miercoles  04         3\n",
       "37             Martes  10         3\n",
       "33             Martes  06         3\n",
       "15             Jueves  07         3\n",
       "43          Miercoles  06         2\n",
       "34             Martes  07         2\n",
       "67            Viernes  07         2\n",
       "44          Miercoles  07         2\n",
       "66            Viernes  06         1\n",
       "22              Lunes  04         1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5.- Haz un merge de la columna dia_de_la_semana del df_sii al dataframe df_bc_all. Luego, extiende\n",
    "#la variable dia_de_la_semana para todos los valores. Finalmente, crea una variable con las combinaciones\n",
    "#[dia,mes] que tienen al menos un NaN que sea en día de semana (es decir, excluyendo Sábado y Domingo).\n",
    "#Luego, cuenta cuantos NaN(incluyendo Sábados y Domingos) hay para cada combinación[dia/mes].\n",
    "#¿Qué puedes inferir de los días con mayor cantidad de NaN?\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_bc_all[\"fecha\"] = pd.to_datetime(df_bc_all[\"Periodo\"])\n",
    "def my_func(row):\n",
    "    return row.dayofweek\n",
    "df_bc_all[\"dia_de_la_semana\"] =  df_bc_all['fecha'].apply(lambda x: my_func(x) if(pd.notnull(x)) else -1)\n",
    "df_bc_all[\"dia_de_la_semana\"] = np.where(df_bc_all['dia_de_la_semana']==0, 'Lunes',\n",
    "              np.where(df_bc_all['dia_de_la_semana']==1, 'Martes',\n",
    "              np.where(df_bc_all['dia_de_la_semana']==2, 'Miercoles',\n",
    "              np.where(df_bc_all['dia_de_la_semana']==3, 'Jueves',\n",
    "              np.where(df_bc_all['dia_de_la_semana']==4, 'Viernes',\n",
    "              np.where(df_bc_all['dia_de_la_semana']==5, 'Sabado',\n",
    "              np.where(df_bc_all['dia_de_la_semana']==6, 'Domingo', 'NA')))))))\n",
    "\n",
    "\n",
    "df_bc_all[\"date_str\"] = df_bc_all['year'].astype(str)+\"-\"+df_bc_all[\"mes\"].astype(str)+\"-\"+df_bc_all[\"dia\"].astype(str)\n",
    "df_bc_all['Date'] = pd.to_datetime(df_bc_all['date_str'])\n",
    "\n",
    "df_bc_all2 = pd.merge(df_bc_all,df_sii, how=\"left\",on=\"date_str\")\n",
    "\n",
    "#crea una variable con las combinaciones\n",
    "#[dia,mes] que tienen al menos un NaN que sea en día de semana \n",
    "df_nan_lunes_a_viernes = df_bc_all2[(df_bc_all2.dia_de_la_semana_x != \"Domingo\") & (df_bc_all2.dia_de_la_semana_x != \"Sabado\") & (df_bc_all2['1.Dólar observado'].isnull())]\n",
    "\n",
    "#df_nan_lunes_a_viernes\n",
    "#obtener la combinacion dia mes que tienen conteos mayores a cero\n",
    "df_nan_lunes_a_viernes_agrupado = df_nan_lunes_a_viernes.groupby(['dia_de_la_semana_x','mes'])['date_str'].count()\n",
    "\n",
    "#df_nan_lunes_a_viernes_agrupado\n",
    "\n",
    "#Luego, cuenta cuantos NaN(incluyendo Sábados y Domingos) hay para cada combinación[dia/mes]\n",
    "df_nan_lunes_a_viernes_agrupado = df_nan_lunes_a_viernes_agrupado.reset_index()\n",
    "\n",
    "#df_nan_lunes_a_viernes_agrupado\n",
    "\n",
    "df_nan_lunes_a_viernes_agrupado[\"day_month\"] = df_nan_lunes_a_viernes_agrupado[\"dia_de_la_semana_x\"].astype(str)+\"_\"+df_nan_lunes_a_viernes_agrupado[\"mes\"].astype(str)\n",
    "\n",
    "#df_nan_lunes_a_viernes_agrupado\n",
    "\n",
    "df_nan_all_week = df_bc_all2[df_bc_all2['1.Dólar observado'].isnull()]\n",
    "\n",
    "df_nan_all_week_agrupado = df_nan_all_week.groupby(['dia_de_la_semana_x','mes'])['date_str'].count()\n",
    "\n",
    "df_nan_all_week_agrupado = df_nan_all_week_agrupado.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "df_nan_all_week_agrupado = df_nan_all_week_agrupado.sort_values(by=['date_str'], ascending=False)\n",
    "\n",
    "df_nan_all_week_agrupado\n",
    "\n",
    "#que se puede concluir de estas agrupaciones?\n",
    "# del listado ordenado se puede ver que entre 1983 y 2021 hay mas dias de agosto\n",
    "#que caen en sabado y domingo que otros meses\n",
    "\n",
    "# de los dias laborales, podemos ver que en el listado aparecen los viernes de abril\n",
    "# como el dia laboral que ha tenido mas valores en nan que todos los otros , lo que \n",
    "#tiene sentido ya que semana santa es como uno de los feriados en que el dia feriado\n",
    "#cae 'obligatoriamente' en dia viernes\n",
    "\n",
    "# a continuacion con los lunes de junio,septiembre y octubre, el de\n",
    "# septiembre tiene sentido por las fiestas patrias, el de junio es de\n",
    "# san pedro y san pablo y en octubre el dia del descubrimiento de america\n",
    "# estos estan al topo del conteo en los dias laborales y es porque\n",
    "# es un feriado fijo y desde la ley que mueve ese tipo de feriados a los lunes\n",
    "# hace sentido que aumente el conteo\n",
    "\n",
    "#fuente que muestra que los feriados que se mueven a los lunes son de junio y octubre:\n",
    "#https://www.dt.gob.cl/portal/1628/w3-article-60252.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "415685b828bd4c1fa122ddb088a61937",
    "deepnote_cell_height": 192.5625,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2547,
    "execution_start": 1663212882484,
    "source_hash": "7ebb4154",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fsspec in c:\\users\\zine5\\anaconda3\\lib\\site-packages (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "310a42a437a84cf99b911db385ed7632",
    "deepnote_cell_height": 2599,
    "deepnote_cell_type": "code",
    "deepnote_table_loading": false,
    "deepnote_table_state": {
     "filters": [],
     "pageIndex": 0,
     "pageSize": 100,
     "sortBy": []
    },
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 773,
    "execution_start": 1663212884298,
    "source_hash": "a7221136",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>1.Dólar observado_x</th>\n",
       "      <th>1.Dólar observado_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1983</td>\n",
       "      <td>80.010000</td>\n",
       "      <td>78.766561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984</td>\n",
       "      <td>102.280000</td>\n",
       "      <td>98.233494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>171.713333</td>\n",
       "      <td>160.725840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1986</td>\n",
       "      <td>191.540000</td>\n",
       "      <td>192.868112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>220.606667</td>\n",
       "      <td>219.456129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1988</td>\n",
       "      <td>244.788000</td>\n",
       "      <td>244.987968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1989</td>\n",
       "      <td>271.305000</td>\n",
       "      <td>266.494777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1990</td>\n",
       "      <td>311.873333</td>\n",
       "      <td>304.679757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1991</td>\n",
       "      <td>357.226667</td>\n",
       "      <td>349.114859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1992</td>\n",
       "      <td>365.230000</td>\n",
       "      <td>362.696145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1993</td>\n",
       "      <td>409.675000</td>\n",
       "      <td>404.255238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1994</td>\n",
       "      <td>414.342000</td>\n",
       "      <td>420.252421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1995</td>\n",
       "      <td>391.543333</td>\n",
       "      <td>396.782056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1996</td>\n",
       "      <td>414.350000</td>\n",
       "      <td>412.219040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1997</td>\n",
       "      <td>416.713333</td>\n",
       "      <td>419.248795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1998</td>\n",
       "      <td>465.580000</td>\n",
       "      <td>460.319719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1999</td>\n",
       "      <td>519.420000</td>\n",
       "      <td>508.897251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2000</td>\n",
       "      <td>544.260000</td>\n",
       "      <td>538.871129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2001</td>\n",
       "      <td>654.450000</td>\n",
       "      <td>634.428502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2002</td>\n",
       "      <td>705.903333</td>\n",
       "      <td>689.242450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2003</td>\n",
       "      <td>696.933333</td>\n",
       "      <td>691.535560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2004</td>\n",
       "      <td>601.967500</td>\n",
       "      <td>609.549960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2005</td>\n",
       "      <td>550.650000</td>\n",
       "      <td>559.862778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2006</td>\n",
       "      <td>534.473333</td>\n",
       "      <td>530.263052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2007</td>\n",
       "      <td>514.896667</td>\n",
       "      <td>522.690688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2008</td>\n",
       "      <td>492.566667</td>\n",
       "      <td>521.789560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2009</td>\n",
       "      <td>556.283333</td>\n",
       "      <td>559.667320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2010</td>\n",
       "      <td>496.472500</td>\n",
       "      <td>510.376640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2011</td>\n",
       "      <td>490.276000</td>\n",
       "      <td>483.364048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2012</td>\n",
       "      <td>485.690000</td>\n",
       "      <td>486.746559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2013</td>\n",
       "      <td>511.076667</td>\n",
       "      <td>494.995161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2014</td>\n",
       "      <td>567.366667</td>\n",
       "      <td>570.005904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2015</td>\n",
       "      <td>667.370000</td>\n",
       "      <td>654.249000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2016</td>\n",
       "      <td>670.732000</td>\n",
       "      <td>676.832421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2017</td>\n",
       "      <td>646.756667</td>\n",
       "      <td>649.328785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2018</td>\n",
       "      <td>662.916667</td>\n",
       "      <td>640.290772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019</td>\n",
       "      <td>731.460000</td>\n",
       "      <td>702.631048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2020</td>\n",
       "      <td>795.436667</td>\n",
       "      <td>792.221833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2021</td>\n",
       "      <td>778.922500</td>\n",
       "      <td>759.272840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  1.Dólar observado_x  1.Dólar observado_y\n",
       "0   1983            80.010000            78.766561\n",
       "1   1984           102.280000            98.233494\n",
       "2   1985           171.713333           160.725840\n",
       "3   1986           191.540000           192.868112\n",
       "4   1987           220.606667           219.456129\n",
       "5   1988           244.788000           244.987968\n",
       "6   1989           271.305000           266.494777\n",
       "7   1990           311.873333           304.679757\n",
       "8   1991           357.226667           349.114859\n",
       "9   1992           365.230000           362.696145\n",
       "10  1993           409.675000           404.255238\n",
       "11  1994           414.342000           420.252421\n",
       "12  1995           391.543333           396.782056\n",
       "13  1996           414.350000           412.219040\n",
       "14  1997           416.713333           419.248795\n",
       "15  1998           465.580000           460.319719\n",
       "16  1999           519.420000           508.897251\n",
       "17  2000           544.260000           538.871129\n",
       "18  2001           654.450000           634.428502\n",
       "19  2002           705.903333           689.242450\n",
       "20  2003           696.933333           691.535560\n",
       "21  2004           601.967500           609.549960\n",
       "22  2005           550.650000           559.862778\n",
       "23  2006           534.473333           530.263052\n",
       "24  2007           514.896667           522.690688\n",
       "25  2008           492.566667           521.789560\n",
       "26  2009           556.283333           559.667320\n",
       "27  2010           496.472500           510.376640\n",
       "28  2011           490.276000           483.364048\n",
       "29  2012           485.690000           486.746559\n",
       "30  2013           511.076667           494.995161\n",
       "31  2014           567.366667           570.005904\n",
       "32  2015           667.370000           654.249000\n",
       "33  2016           670.732000           676.832421\n",
       "34  2017           646.756667           649.328785\n",
       "35  2018           662.916667           640.290772\n",
       "36  2019           731.460000           702.631048\n",
       "37  2020           795.436667           792.221833\n",
       "38  2021           778.922500           759.272840"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6.-Calcula el promedio del precio del dolar en los días de cumpleaños del grupo para cada año entre\n",
    "# 1983 y 2021 y el promedio del precio del dolar para cada año completo entre 1983 y 2021, y muestra\n",
    "# una tabla donde se vean ambos resultados. ¿Qué diferencias hay en ambos indicadores en cada año?\n",
    "\n",
    "#i1 Ricardo Ovando 23/09 \n",
    "#i2 Felipe Bello 06/12 \n",
    "#i3 Roberto Monsalves 14/09 \n",
    "#i4 Angélica Cid 13/06 \n",
    "#i5 Camilo Olavarria 14/04\n",
    "\n",
    "df_cumple = pd.read_csv(\"https://raw.githubusercontent.com/rovandof/tarea1-add/master/Integrantes-rovandof.md\",index_col = 0,delimiter=\" \",header=None)\n",
    "\n",
    "\n",
    "df_cumple[[\"dia\",\"mes\"]] = df_cumple[3].str.split(\"/\", expand=True)\n",
    "\n",
    "df_bc_cumple = pd.merge(df_cumple,df_bc_all,on=[\"dia\",\"mes\"])\n",
    "\n",
    "df_bc_cumple_filtrado = df_bc_cumple[(df_bc_cumple.year != 2022) & (df_bc_cumple.year != 1982)]\n",
    "\n",
    "\n",
    "df_result = df_bc_cumple_filtrado.groupby('year')['1.Dólar observado'].mean()\n",
    "df_result = df_result.reset_index()\n",
    "\n",
    "\n",
    "df_result2 = df_bc_all.groupby('year')['1.Dólar observado'].mean()\n",
    "df_result2 = df_result2.reset_index()\n",
    "df_result2_filtrado = df_result2[(df_result2.year != 2022) & (df_result2.year != 1982)]\n",
    "\n",
    "#df_result\n",
    "#df_result2_filtrado\n",
    "\n",
    "df_comparacion = pd.merge(df_result,df_result2_filtrado,on=\"year\")\n",
    "\n",
    "df_comparacion\n",
    "\n",
    "#Los días de cumpleaños corresponden a una muestra aleatoria de días del mes, al calcular el promedio  \n",
    "#del valor del Dolar en estos días observamos que la tendencia es similar al valor promedio de la población \n",
    "#total, por lo que podemos inferir que la muestra es representativa. \n",
    "\n",
    "#Los datos muestran el alza del precio del dolar.\n",
    "\n",
    "#El precio del dolar anual en la mayoría de los casos es menor y eso es debido a que el promedio considera\n",
    "#todos los días del año incluso los fines de semana y festivo, los cuales en la base tienen valor de 0.0, \n",
    "#lo que implica que baje el promedio anual \n",
    "#Por otro lado, el precio del dolar según los cumpleaños será más bajo o no, si aquellos cumpleaños \n",
    "#caen, en fines de semana o días festivos"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "c4310ea9-5642-44ff-b723-a134a6f0c711",
  "deepnote_persisted_session": {
   "createdAt": "2022-09-15T04:01:36.346Z"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
